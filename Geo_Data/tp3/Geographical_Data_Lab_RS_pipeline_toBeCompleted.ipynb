{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Remote Sensing Lab : Setup a RS pipeline to respond to an actual use case !**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vincent Delbar - Antoine Gademer - Bastien Nguyen-Duy / 2023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Objectifs : \n",
        "\n",
        "PART1: (3h) Discovery of a RS pipeline\n",
        "1. Find an Area of Interest by filtering geoportal commune layer --> Export the bounding box\n",
        "2. Searching relevant images in the Copernicus catalog\n",
        "3. Actually downloading the images from the Sentinel Dataspace\n",
        "4. Image processing on Sentinel-2 images :  True-color, False-color\n",
        "5. High level processing with SentinelHub library\n",
        "6. Application to the analysis of the fire in La Teste-de-Buch \n",
        "\n",
        "PART2: (3h) Build a RS pipeline to solve your own Use case!\n",
        "\n",
        "Prerequisite :\n",
        "\n",
        "- Manipulate vector data in python (and understand CRS)\n",
        "- Manipulate and display 16bit images in python\n",
        "- Understand the concept of Spectral Signature\n",
        "- Interacte with an API in python\n",
        "- Need to create a free accound on SentinelHub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Find an Area of Interest\n",
        "\n",
        "Satelitte sensors can acquire data all over the world. The data availlable in the catalogs can be overwhelming. It is therefore primordial to know WHERE you want to look.\n",
        "\n",
        "Let's say we want to explore the impact of the fires that have impacted the Gironde department from July to August 2022.\n",
        "\n",
        "https://fr-m-wikipedia-org.translate.goog/wiki/Feux_de_for%C3%AAt_de_2022_en_Gironde?_x_tr_sl=fr&_x_tr_tl=en&_x_tr_hl=fr&_x_tr_pto=wapp\n",
        "\n",
        "The fire started in the municipalities of \"La Teste-de-Buch\" so we will concentrate our study in this zone."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using the geoportal WFS server\n",
        "\n",
        "In France, National Geographic Institute (IGN) is responsible of producing, selling and sharing all geographical data concerning the France territory.\n",
        "\n",
        "One of it's main product is the \"BD TOPO\", a collection of vector layers on many subjects : roads, rivers... and municipalites (\"communes\" in French)\n",
        "\n",
        "There is many way to access it. For this exercise, we propose you to use the geoportal WFS API accessible through the URL : \n",
        "\n",
        "```\n",
        "https://wxs.ign.fr/topographie/geoportail/wfs?SERVICE=WFS&VERSION=2.0.0&request=GetFeature&OUTPUTFORMAT=application/json&typename=BDTOPO_V3:commune\n",
        "```\n",
        "\n",
        "⚠ With 35000 municipalites in France, we counsel you to add a filtering parameter at the end : \n",
        "```\n",
        "&CQL_FILTER=code_insee_du_departement=33\n",
        "```\n",
        "(Nota Bene : 33 is the zipcode of the Gironde department)\n",
        "\n",
        "⚠ Side note. If you read this *after December 31th 2023*, the urls/protocols will have changed. More info : https://geoservices.ign.fr/bascule-vers-la-geoplateforme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<details>\n",
        "\n",
        "<summary>Tips</summary>\n",
        "\n",
        "Geopandas is able to read directly the WFS url.\n",
        "We can also downloaded the json file and opened it locally.\n",
        "\n",
        "```python\n",
        "municipalities = geopandas.read_file(wfs_url)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<details>\n",
        "\n",
        "<summary>Help : I have a timeout error message...</summary>\n",
        "\n",
        "If you got a timeout error message, you can also try to click on the link/open it in your web browser and save it as a JSON file locally. Then you'll be able to read it with geopandas.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: geopandas in /home/zhangsanbao/miniconda3/envs/data_e/lib/python3.11/site-packages (0.14.0)\n",
            "Collecting folium\n",
            "  Downloading folium-0.14.0-py2.py3-none-any.whl (102 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.3/102.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /home/zhangsanbao/miniconda3/envs/data_e/lib/python3.11/site-packages (3.8.0)\n",
            "Collecting mapclassify\n",
            "  Obtaining dependency information for mapclassify from https://files.pythonhosted.org/packages/27/38/9ee51b78d134301c359b67ea6b493a9a60bca67ea044f8114387d0c4d7e7/mapclassify-2.6.0-py3-none-any.whl.metadata\n",
            "  Downloading mapclassify-2.6.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: fiona>=1.8.21 in /home/zhangsanbao/miniconda3/envs/data_e/lib/python3.11/site-packages (from geopandas) (1.9.4.post1)\n",
            "Requirement already satisfied: packaging in /home/zhangsanbao/miniconda3/envs/data_e/lib/python3.11/site-packages (from geopandas) (23.1)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /home/zhangsanbao/miniconda3/envs/data_e/lib/python3.11/site-packages (from geopandas) (2.1.0)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /home/zhangsanbao/miniconda3/envs/data_e/lib/python3.11/site-packages (from geopandas) (3.6.1)\n",
            "Requirement already satisfied: shapely>=1.8.0 in /home/zhangsanbao/miniconda3/envs/data_e/lib/python3.11/site-packages (from geopandas) (2.0.1)\n",
            "Collecting branca>=0.6.0 (from folium)\n",
            "  Downloading branca-0.6.0-py3-none-any.whl (24 kB)\n",
            "Collecting jinja2>=2.9 (from folium)\n",
            "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "Requirement already satisfied: numpy in /home/zhangsanbao/miniconda3/envs/data_e/lib/python3.11/site-packages (from folium) (1.26.0)\n",
            "Collecting requests (from folium)\n",
            "  Obtaining dependency information for requests from https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl.metadata\n",
            "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/zhangsanbao/miniconda3/envs/data_e/lib/python3.11/site-packages (from matplotlib) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/zhangsanbao/miniconda3/envs/data_e/lib/python3.11/site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/zhangsanbao/miniconda3/envs/data_e/lib/python3.11/site-packages (from matplotlib) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/zhangsanbao/miniconda3/envs/data_e/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /home/zhangsanbao/miniconda3/envs/data_e/lib/python3.11/site-packages (from matplotlib) (10.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/zhangsanbao/miniconda3/envs/data_e/lib/python3.11/site-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/zhangsanbao/miniconda3/envs/data_e/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
            "Collecting scipy>=1.0 (from mapclassify)\n",
            "  Obtaining dependency information for scipy>=1.0 from https://files.pythonhosted.org/packages/ef/1b/7538792254aec6850657d5b940fd05fe60582af829ffe40d6c054f065f34/scipy-1.11.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached scipy-1.11.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting scikit-learn (from mapclassify)\n",
            "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/8f/87/5969092159207f583481ad80a03f09e2d4af1ebd197f4530ca4e906c947e/scikit_learn-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached scikit_learn-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting networkx (from mapclassify)\n",
            "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /home/zhangsanbao/miniconda3/envs/data_e/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas) (23.1.0)\n",
            "Requirement already satisfied: certifi in /home/zhangsanbao/miniconda3/envs/data_e/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas) (2023.7.22)\n",
            "Requirement already satisfied: click~=8.0 in /home/zhangsanbao/miniconda3/envs/data_e/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas) (8.1.7)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /home/zhangsanbao/miniconda3/envs/data_e/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /home/zhangsanbao/miniconda3/envs/data_e/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas) (0.7.2)\n",
            "Requirement already satisfied: six in /home/zhangsanbao/miniconda3/envs/data_e/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas) (1.16.0)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2>=2.9->folium)\n",
            "  Obtaining dependency information for MarkupSafe>=2.0 from https://files.pythonhosted.org/packages/fe/21/2eff1de472ca6c99ec3993eab11308787b9879af9ca8bbceb4868cf4f2ca/MarkupSafe-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached MarkupSafe-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/zhangsanbao/miniconda3/envs/data_e/lib/python3.11/site-packages (from pandas>=1.4.0->geopandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/zhangsanbao/miniconda3/envs/data_e/lib/python3.11/site-packages (from pandas>=1.4.0->geopandas) (2023.3)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->folium)\n",
            "  Obtaining dependency information for charset-normalizer<4,>=2 from https://files.pythonhosted.org/packages/ff/b6/9222090f396f33cd58aa5b08b9bbf8871416b746a0c7b412a41a973674a5/charset_normalizer-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached charset_normalizer-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->folium)\n",
            "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->folium)\n",
            "  Obtaining dependency information for urllib3<3,>=1.21.1 from https://files.pythonhosted.org/packages/37/dc/399e63f5d1d96bb643404ee830657f4dfcf8503f5ba8fa3c6d465d0c57fe/urllib3-2.0.5-py3-none-any.whl.metadata\n",
            "  Using cached urllib3-2.0.5-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting joblib>=1.1.1 (from scikit-learn->mapclassify)\n",
            "  Obtaining dependency information for joblib>=1.1.1 from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
            "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=2.0.0 (from scikit-learn->mapclassify)\n",
            "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n",
            "  Using cached threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
            "Downloading mapclassify-2.6.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached scipy-1.11.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "Using cached scikit_learn-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
            "Using cached charset_normalizer-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
            "Using cached MarkupSafe-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Using cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
            "Using cached urllib3-2.0.5-py3-none-any.whl (123 kB)\n",
            "Installing collected packages: urllib3, threadpoolctl, scipy, networkx, MarkupSafe, joblib, idna, charset-normalizer, scikit-learn, requests, jinja2, mapclassify, branca, folium\n",
            "Successfully installed MarkupSafe-2.1.3 branca-0.6.0 charset-normalizer-3.3.0 folium-0.14.0 idna-3.4 jinja2-3.1.2 joblib-1.3.2 mapclassify-2.6.0 networkx-3.1 requests-2.31.0 scikit-learn-1.3.1 scipy-1.11.3 threadpoolctl-3.2.0 urllib3-2.0.5\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install geopandas folium matplotlib mapclassify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import geopandas as gpd\n",
        "import folium\n",
        "import matplotlib\n",
        "import mapclassify\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "import geopandas as gpd\n",
        "import folium\n",
        "import matplotlib\n",
        "import "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here\n",
        "\n",
        "wfs_url = 'https://wxs.ign.fr/topographie/geoportail/wfs?SERVICE=WFS&VERSION=2.0.0&request=GetFeature&OUTPUTFORMAT=application/json&typename=BDTOPO_V3:commune'\n",
        "municipalities=gpd.read_file(wfs_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Bonus** : If you want to explore a GeoDataframes by displaying it on a map with leaflet/folium you can use the ```explore()``` function.\n",
        "\n",
        "Note : Explore don't like the Timestamp type, so we exclude the corresponding columns.\n",
        "```\n",
        "municipalities.loc[:,~municipalities.columns.isin(['date_creation', 'date_modification'])].explore()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "The 'folium', 'matplotlib' and 'mapclassify' packages are required for 'explore()'. You can install them using 'conda install -c conda-forge folium matplotlib mapclassify' or 'pip install folium matplotlib mapclassify'.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "File \u001b[0;32m~/miniconda3/envs/data_e/lib/python3.11/site-packages/geopandas/explore.py:281\u001b[0m, in \u001b[0;36m_explore\u001b[0;34m(df, column, cmap, color, m, tiles, attr, tooltip, popup, highlight, categorical, legend, scheme, k, vmin, vmax, width, height, categories, classification_kwds, control_scale, marker_type, marker_kwds, style_kwds, highlight_kwds, missing_kwds, tooltip_kwds, popup_kwds, legend_kwds, map_kwds, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 281\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mbranca\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mbc\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mfolium\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'branca'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32m/home/zhangsanbao/Project/School_Things/Geo_Data/tp3/Geographical_Data_Lab_RS_pipeline_toBeCompleted.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/zhangsanbao/Project/School_Things/Geo_Data/tp3/Geographical_Data_Lab_RS_pipeline_toBeCompleted.ipynb#Y156sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m municipalities\u001b[39m.\u001b[39;49mloc[:, \u001b[39m~\u001b[39;49mmunicipalities\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49misin([\u001b[39m'\u001b[39;49m\u001b[39mdate_creation\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mdate_modification\u001b[39;49m\u001b[39m'\u001b[39;49m])]\u001b[39m.\u001b[39;49mexplore()\n",
            "File \u001b[0;32m~/miniconda3/envs/data_e/lib/python3.11/site-packages/geopandas/geodataframe.py:2113\u001b[0m, in \u001b[0;36mGeoDataFrame.explore\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2111\u001b[0m \u001b[39m@doc\u001b[39m(_explore)\n\u001b[1;32m   2112\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexplore\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 2113\u001b[0m     \u001b[39mreturn\u001b[39;00m _explore(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/miniconda3/envs/data_e/lib/python3.11/site-packages/geopandas/explore.py:297\u001b[0m, in \u001b[0;36m_explore\u001b[0;34m(df, column, cmap, color, m, tiles, attr, tooltip, popup, highlight, categorical, legend, scheme, k, vmin, vmax, width, height, categories, classification_kwds, control_scale, marker_type, marker_kwds, style_kwds, highlight_kwds, missing_kwds, tooltip_kwds, popup_kwds, legend_kwds, map_kwds, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m cm\n\u001b[1;32m    296\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mImportError\u001b[39;00m, \u001b[39mModuleNotFoundError\u001b[39;00m):\n\u001b[0;32m--> 297\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m    298\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfolium\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39mmapclassify\u001b[39m\u001b[39m'\u001b[39m\u001b[39m packages are required for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mexplore()\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. You can install them using \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconda install -c conda-forge folium matplotlib mapclassify\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    301\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpip install folium matplotlib mapclassify\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m     )\n\u001b[1;32m    304\u001b[0m \u001b[39m# xyservices is an optional dependency\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
            "\u001b[0;31mImportError\u001b[0m: The 'folium', 'matplotlib' and 'mapclassify' packages are required for 'explore()'. You can install them using 'conda install -c conda-forge folium matplotlib mapclassify' or 'pip install folium matplotlib mapclassify'."
          ]
        }
      ],
      "source": [
        "municipalities.loc[:, ~municipalities.columns.isin(['date_creation', 'date_modification'])].explore()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Find the row corresponding to \"La Teste-de-Buch\" municipalites then use the plot() function to show the zone."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<details>\n",
        "\n",
        "<summary>Tips</summary>\n",
        "\n",
        "You can use the columns property of the geopandas to look for columns that could help you filter the rows.\n",
        "```\n",
        "print(municipalities.columns)\n",
        "```\n",
        "For non-native speaker, \"nom_officiel\" is the official name of the municipalities (a good starting point ?). \"code_insee\" is a unique code associated to each municipalities. Most of the time you can find this code on internet : https://www.google.com/search?q=la+teste+de+buch+code+insee\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<details>\n",
        "\n",
        "<summary>Help : I have 0 results... :(</summary>\n",
        "\n",
        "Check that your test is valid. Is the municipalities name exactly the one expected ? Is the code_insee a number or a string ?\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here\n",
        "area_of_interest= ... \n",
        "\n",
        "#You can use\n",
        "display(area_of_interest.iloc[0][\"geometry\"])\n",
        "#or\n",
        "area_of_interest.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check the CRS of your row (``display(area_of_interest.crs)``). You may need this information later 😊"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract the bounding box of the zone (we don't need to give a complex geometry to the search function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<details>\n",
        "\n",
        "<summary>Tips</summary>\n",
        "\n",
        "**bounds** will give you the bounds of each row, you then need to select the first one\n",
        "\n",
        "**total_bounds** will give you the bounds of all the rows (even if their is only one in our case 😛)\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shapely\n",
        "\n",
        "#Your code here\n",
        "aoi_bbox = ...    # The bounding box of your area of interest. Which bounds will you choose ?\n",
        "\n",
        "aoi_bbox_rect=[(aoi_bbox[1],aoi_bbox[0]), (aoi_bbox[3],aoi_bbox[2])] # [(miny,minx), (maxy,maxx)] : Lat,Lon means that y is first\n",
        "aoi_bbox_polygon = shapely.geometry.box(*aoi_bbox)\n",
        "display(aoi_bbox)\n",
        "display(aoi_bbox_rect) # As two points Northeast and Southwest\n",
        "print(aoi_bbox_polygon) # As a polygon\n",
        "display(aoi_bbox_polygon)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bonus : Verifying what we are doing (with folium)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import folium\n",
        "folium_tile='OpenStreetMap' # Default\n",
        "#folium_tile='stamenwatercolor' # For Artists\n",
        "#folium_tile='CartoDB Positron' # Discrete\n",
        "#folium_tile='CartoDB Dark_matter' # Paint it black\n",
        "\n",
        "map_osm = folium.Map(tiles=folium_tile)\n",
        "map_osm.add_child(folium.GeoJson(data=aoi_bbox_polygon, style_function=lambda x: {'color': 'blue'})) # GeoJson need the Polygon format\n",
        "map_osm.add_child(folium.GeoJson(data=area_of_interest[\"geometry\"].to_json(), style_function=lambda x: {'color': 'black','fillColor': 'orange'}))\n",
        "map_osm.fit_bounds(aoi_bbox_rect) # fit bounds need the NE-SW format\n",
        "map_osm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Searching relevant images in the Copernicus catalog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The objective for Copernicus program from ESA (European Space Agency) is to **use vast amount of global data from satellites** and from ground-based, airborne and seaborne measurement systems **to produce timely and quality information, services and knowledge**, and to provide autonomous and independent access to information in the domains of environment and security on a global level in order to help service providers, public authorities and other international organizations improve the quality of life for the citizens of Europe. In other words, it pulls together all the information obtained by the Copernicus environmental satellites, air and ground stations and sensors to provide a comprehensive picture of the \"health\" of Earth.\n",
        "\n",
        "One of the benefits of the Copernicus programme is that the data and information produced in the framework of Copernicus are made available **free-of-charge** to all its users and the public, thus allowing downstream services to be developed.\n",
        "\n",
        "Source : https://en.wikipedia.org/wiki/Copernicus_Programme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note it exists several access to these Data but that **Copernicus Data Space Ecosystem is the new way to follow** (since Jan 2023) and that other channel will be deprecated at the End of Sept. 2023."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sources : \n",
        "\n",
        "https://dataspace.copernicus.eu/news/2023-7-13-accessing-sentinel-mission-data-new-copernicus-data-space-ecosystem-apis\n",
        "\n",
        "https://github.com/eu-cdse/notebook-samples/blob/c0e0ade601973c5d4e4bf66a13c0b76ebb099805/sentinelhub/migration_from_scihub_guide.ipynb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## OData\n",
        "OData (Open Data Protocol) is a standard that specifies a variety of best practices for creating and using REST APIs. OData makes it possible to build REST-based data services that let Web clients publish and edit resources that are recognized by Uniform Resource Locators (URLs) and described in a data model using straightforward HTTP messages. This is the method you will want to use if your workflow requires the download of **full products**/granules/tiles. \n",
        "\n",
        "⚠ Full products archive are generally around 1Go each. **Downloading them require generaly a long time.**\n",
        "\n",
        "The documentation regarding this can be found [here](https://documentation.dataspace.copernicus.eu/APIs/OData.html).\n",
        "\n",
        "In this example, we will search the catalogue, generate the required credentials and then download a Sentinel-2 L2A granule using this protocol:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setting our search parameters\n",
        "\n",
        "Firstly, we need to define our `start_date` and `end_date`, the `data_collection` and the area of interest (`aoi`). We define them in the next cell and will insert them into our request as string variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**For the moment, we will consider the period before the fire**, let say from start of April to end of June 2022."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here\n",
        "start_date = ...\n",
        "end_date = ...\n",
        "data_collection = \"SENTINEL-2\"\n",
        "product_type = \"S2MSI2A\" # Level 2A products (cf. https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/product-types/level-2a)\n",
        "print(aoi_bbox_polygon)  # Set from previous section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To search the catalogue we use the following code block:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import requests\n",
        "url=\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?\" \\\n",
        "+\"$filter=Collection/Name eq '{}'\".format(data_collection) \\\n",
        "+\" and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq '{}')\".format(product_type) \\\n",
        "+\" and OData.CSC.Intersects(area=geography'SRID=4326;{}')\".format(aoi_bbox_polygon) \\\n",
        "+\" and ContentDate/Start gt {}T00:00:00.000Z\".format(start_date) \\\n",
        "+\" and ContentDate/Start lt {}T00:00:00.000Z\".format(end_date) \\\n",
        "+\"&$expand=Assets\" \\\n",
        "+\"&$expand=Attributes\" \\\n",
        "+\"&$orderby=ContentDate/Start\" \\\n",
        "+\"&$top=50\"\n",
        "print(url)\n",
        "product_json = requests.get(url).json()\n",
        "if \"detail\" in product_json: #Error int the requests\n",
        "    print(product_json)\n",
        "else:\n",
        "    products = pd.DataFrame.from_dict(product_json['value'])\n",
        "    print(\"Found: {}\".format(len(products)))\n",
        "    display(products)\n",
        "    display(products.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question : How many image are available for your criteria ? What is the date of the image acquisition ? The cloud coverage ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Cloud cover information is hidden in the Attributes field. Use the following line to extract it :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "products[\"cloudCover\"] = [attribute[\"Value\"] for attribute in products[\"Attributes\"].explode() if attribute[\"Name\"] == 'cloudCover'] # Dark magic. You may try to execute by pieces to understand how it works\n",
        "products[[\"OriginDate\",\"cloudCover\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Question : What can you say about the proportion of **usable** images ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The catalog contains a Quicklook image. \n",
        "\n",
        "The url to the image is hidden in the Assets field.\n",
        "```\n",
        "products[\"Assets\"].iloc[idx][0]['DownloadLink'] # Copernicus arbitray Assets field organisation\n",
        "```\n",
        "\n",
        "Once displayed, Ctrl+Click on it to download it with you web browser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following function can be used to download and display remote images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "def showRemoteImage(image_url):\n",
        "    # Download the image using requests\n",
        "    my_res = requests.get(image_url)\n",
        "    if my_res.status_code == 200:\n",
        "        # Open the downloaded image in PIL\n",
        "        my_img = Image.open(BytesIO(my_res.content))\n",
        "        # Show the image\n",
        "        display(my_img)\n",
        "    else:\n",
        "        display(my_res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use it to display the Quicklook in your notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ipywidget is a library that you can use to have interactive user interface.\n",
        "\n",
        "We can combine it with the previous function, to obtain a nice usable tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ipywidgets\n",
        "\n",
        "def selectionWidget(products,selectedColumns):\n",
        "    def loadQuickLook(idx=0):\n",
        "        showRemoteImage(products[\"Assets\"].iloc[idx][0]['DownloadLink']) \n",
        "        return products[selectedColumns].iloc[idx]\n",
        "    ipywidgets.interact(loadQuickLook,  idx=(0, products.shape[0]-1))\n",
        "\n",
        "selectionWidget(products,['OriginDate','cloudCover','Online'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Wouldn't it be more efficient to filter on cloudCover directly ?\n",
        "\n",
        "You're right.\n",
        "In a new cell, copypaste the code of the request and **add the following criteria to your url**.\n",
        "```\n",
        "and Attributes/OData.CSC.DoubleAttribute/any(att:att/Name eq 'cloudCover' and att/OData.CSC.DoubleAttribute/Value le 10.00)\n",
        "```\n",
        "(i.e. we want a cloudCover value < 10.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<details>\n",
        "\n",
        "<summary>Tips</summary>\n",
        "You cannot add the criteria anywhere in the request. Check how the <verb>$filter</verb> part is constructed.\n",
        "\n",
        "Also, don't forget the \\ at the end of the line (that allow to break the line in several lines for lisibility)\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract the cloudCover column and show the Quicklook of the image in the ipywidget (Only the minimum necessary copypasting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### A Little detour : productType\n",
        "\n",
        "- Copypaste the request cell, but **remove the productType criteria**.\n",
        "- Extract the cloudCover.\n",
        "- Duplicate the process to also extract the productType from the Attribute field.\n",
        "- Modify the call to selectionWidget to add the \"productType\" column in the information displayed\n",
        "- Show the query result in the ipywidget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Questions :\n",
        "\n",
        "- What is the main visible difference between the level 1C and level 2A ?\n",
        "- If I was a bird, what would I see ?\n",
        "- If I was a high altitude plane, what would I see ?\n",
        "- What is the most helpful for my application ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Note the Id of the desired image and store it for later.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here\n",
        "before_id = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Actually downloading the images from the Sentinel Dataspace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The access to the catalog is public, but you need to be registred to download the data.\n",
        "\n",
        "1. Follow the procedure here to create a free account on Copernicus Dataspace : https://documentation.dataspace.copernicus.eu/Registration.html (Registration + Email validation)\n",
        "2. Create a ```myCopernicusCredentials.py``` file with only two lines :\n",
        "```\n",
        "username=\"name@email.com\"\n",
        "password=\"XXXXXXXXX\"\n",
        "```\n",
        "**⚠ DON'T UPLOAD YOUR CREDENTIAL FILE ON MOODLE. IT IS PERSONNAL AND SECRET !**\n",
        "\n",
        "3. Create an access token with your user/password with the following ```get_keycloak()``` function\n",
        "4. Use the access token to download the image archive\n",
        "\n",
        "**⚠ The archive is really heavy (~1.3Go). You don't need to go until the end of the download** (Square -> interrupt). Just show that you started the download.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "# Function inspired by Copernicus documentation : \n",
        "# - https://documentation.dataspace.copernicus.eu/APIs/Token.html\n",
        "# - https://documentation.dataspace.copernicus.eu/APIs/OData.html#product-download\n",
        "\n",
        "def get_keycloak(username: str, password: str) -> str:\n",
        "    data = {\n",
        "        \"client_id\": \"cdse-public\",\n",
        "        \"username\": username,\n",
        "        \"password\": password,\n",
        "        \"grant_type\": \"password\",\n",
        "        }\n",
        "    try:\n",
        "        r = requests.post(\"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\",\n",
        "        data=data,\n",
        "        )\n",
        "        r.raise_for_status()\n",
        "    except Exception as e:\n",
        "        raise Exception(\n",
        "            f\"Keycloak token creation failed. Reponse from the server was: {r.json()}\"\n",
        "            )\n",
        "    return r.json()[\"access_token\"]       \n",
        "\n",
        "def downloadCopernicusFile(product_id, keycloak_token):\n",
        "    session = requests.Session()\n",
        "    session.headers.update({'Authorization': f'Bearer {keycloak_token}'}) # Authorization header\n",
        "    url = f\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products({product_id})/$value\"\n",
        "    response = session.get(url, allow_redirects=False, stream=True)\n",
        "    while response.status_code in (301, 302, 303, 307):\n",
        "        url = response.headers['Location']\n",
        "        response = session.get(url, allow_redirects=False, stream=True)\n",
        "\n",
        "    file = session.get(url, verify=False, allow_redirects=True, stream=True)\n",
        "    total_size_in_bytes= int(response.headers.get('content-length', 0))\n",
        "    block_size = 1024 #1 Kibibyte\n",
        "    progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True)\n",
        "\n",
        "    if os.path.exists(f\"{product_id}.zip\"):\n",
        "        print(\"ERROR, file already exists\")\n",
        "        return\n",
        "    with open(f\"{product_id}.zip\", 'wb') as file:\n",
        "        for data in response.iter_content(block_size):\n",
        "            progress_bar.update(len(data))\n",
        "            file.write(data)\n",
        "    progress_bar.close()\n",
        "    if total_size_in_bytes != 0 and progress_bar.n != total_size_in_bytes:\n",
        "        print(\"ERROR, something went wrong\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import myCopernicusCredentials\n",
        "\n",
        "#Your code here\n",
        "keycloak_token = ... \n",
        "downloadCopernicusFile(...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<details>\n",
        "\n",
        "<summary>Tips</summary>\n",
        "Once imported you can use ```myCopernicusCredentials.username``` and ```myCopernicusCredentials.password```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**⚠ Note: Previous API had the possibility to download only a part of the archive, but it is not possible currently this the ODATA API to the Copernicus Dataspace.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You will find on Moodle a ```S2B_MSIL2A_20220528T105619_N0400_R094_T30TXQ_20220528T130057.SAFE_subset.zip``` archive where you will find a expurged archive with only the B02,B03,B04,B8A channel at 20m resolution (to keep it \"small\").\n",
        "\n",
        "**If you achieved to download the whole archive, you don't need the Moodle file**, if not, it is a way to continue the Lab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Image processing on Sentinel-2 images :  True-color, False-color\n",
        "\n",
        "Using what you learn in the Image Processing Capsule:\n",
        "1. Load the three 16-bits images with cv2\n",
        "2. Apply a x3.5 factor on the brightness of the channels\n",
        "3. Merge them into a RGB 16-bits image with `np.dstack()`\n",
        "4. Display the image as a 8-bit image in the notebook\n",
        "\n",
        "Do the process twice:\n",
        "- once for a True-color result (B04 as red, B03 as green, B02 as blue).\n",
        "- once for a False-color result (B8A as red, B04 as green, B03 as blue)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. High level processing with SentinelHub library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Accessing data via Sentinel Hub APIs\n",
        "\n",
        "The [Sentinel Hub API](https://documentation.dataspace.copernicus.eu/APIs/SentinelHub.html) is a RESTful API interface that provides access to various satellite imagery archives. It allows you to access raw satellite data, [rendered images](https://documentation.dataspace.copernicus.eu/APIs/SentinelHub/Process.html), [statistical analysis](https://documentation.dataspace.copernicus.eu/APIs/SentinelHub/Statistical.html), and other features. \n",
        "\n",
        "In these examples, we will be using the `sentinelhub` python [package](https://sentinelhub-py.readthedocs.io/en/latest/index.html). The sentinelhub Python package is the official Python interface for [Sentinel Hub](https://www.sentinel-hub.com/) services. The package provides a collection of basic tools and utilities for working with geospatial and satellite data. It builds on top of well known packages such as `numpy`, `shapely`, `pyproj`.\n",
        "\n",
        "To successfully run this notebook, make sure that you install or upgrade ```sentinelhub``` package to at least Version `3.9.1`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Credentials\n",
        "\n",
        "**Nota Bene**: Even SentinelHub try to access the same Copernicus Dataspace, it will require an additional authentification step : the creation of a unique pair client_id/client_secret *dedicated to this API*.\n",
        "\n",
        "To obtain your `client_id` & `client_secret` you need to navigate to your [Dashboard](https://shapps.dataspace.copernicus.eu/dashboard/#/). \n",
        "*(You may require to login with the username/password created in the first part of the Lab)*\n",
        "\n",
        "In the User Settings you can create a new OAuth Client to generate these credentials. For more detailed instructions, visit the relevent [documentation page](https://documentation.dataspace.copernicus.eu/APIs/SentinelHub/Overview/Authentication.html).\n",
        "\n",
        "Instructions on how to configure your Sentinel Hub Python package can be found [here](https://sentinelhub-py.readthedocs.io/en/latest/configure.html). Using these instructions you can create a profile specific to using the package for accessing Copernicus Data Space Ecosystem data collections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add `client_id` and `client_secret` to your `myCopernicusCredentials.py` file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<details>\n",
        "\n",
        "<summary>Help myCopernicusCredentials.client_id doest not exists !</summary>\n",
        "1. Have you added those variable to the myCopernicusCredentials.py file ?\n",
        "2. You may need to restart the Jupyter kernel if you have already imported it previoulsy (probably your case)\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "import myCopernicusCredentials\n",
        "import sentinelhub\n",
        "\n",
        "config = sentinelhub.SHConfig()\n",
        "\n",
        "config.sh_client_id = myCopernicusCredentials.client_id\n",
        "config.sh_client_secret =  myCopernicusCredentials.client_secret\n",
        "config.sh_token_url = \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\"\n",
        "config.sh_base_url = \"https://sh.dataspace.copernicus.eu\"\n",
        "config.save(\"cdse\")\n",
        "# Saved config can be later accessed with config = SHConfig(\"cdse\")\n",
        "\n",
        "config = sentinelhub.SHConfig(\"cdse\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setting an area of interest\n",
        "\n",
        "The bounding box in `WGS84` coordinate system is `[(longitude and latitude coordinates of lower left and upper right corners)]`. \n",
        "\n",
        "If we compare to the previous method where we needed `aoi_bbox_polygon`, here, we only need the simple `aoi_bbox` (created from the `bounds`/`total_bounds` attribute.)\n",
        "\n",
        "**Note**: In the case of a general project, you can find the bounding box of anything zone with the help of the [bboxfinder](http://bboxfinder.com/) website.\n",
        "\n",
        "All requests require a bounding box to be given as an instance of `sentinelhub.geometry.BBox` with corresponding Coordinate Reference System (`sentinelhub.constants.CRS`). In our case it is in WGS84 and we can use the predefined WGS84 coordinate reference system from `sentinelhub.constants.CRS`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#If the aoi_bbox value is still in memory\n",
        "display(type(aoi_bbox),aoi_bbox)\n",
        "#If not, just re-run the corresponding cells (\"Find an Area of Interest\" section)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When the bounding box bounds have been defined, you can initialize the `BBox` of the area of interest. Using the `bbox_to_dimensions` utility function, you can provide the desired resolution parameter of the image in meters and obtain the output image shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image shape at 20 m resolution: (577, 1330) pixels\n"
          ]
        }
      ],
      "source": [
        "resolution = 20\n",
        "aoi_bbox_sh = sentinelhub.BBox(bbox=list(aoi_bbox), crs=sentinelhub.CRS.WGS84)\n",
        "aoi_size = sentinelhub.bbox_to_dimensions(aoi_bbox_sh, resolution=resolution)\n",
        "\n",
        "print(f'Image shape at {resolution} m resolution: {aoi_size} pixels')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Catalog API\n",
        "To search and discover data, you can use the Catalog API. Sentinel Hub Catalog API (or shortly \"Catalog\") is an API implementing the STAC Specification, providing geospatial information for data available in Sentinel Hub. Firstly, to initialise the `SentinelHubCatalog` class we will use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "catalog = sentinelhub.SentinelHubCatalog(config=config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can build the Catalog API request; to do this we use the `aoi_bbox_sh` we defined earlier as well as `time_interval` and insert these into the request:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Note**: `start_date` and `end_date` were set in the \"Searching relevant images in the Copernicus catalog\" section. You can rewrite them here for simplicity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#start_date=...\n",
        "#end_date=...\n",
        "time_interval = start_date, end_date\n",
        "\n",
        "search_iterator = catalog.search(\n",
        "    sentinelhub.DataCollection.SENTINEL2_L2A, # Level 2A from Sentinel-2\n",
        "    bbox=aoi_bbox_sh,                         # Bounding box of the Area of Interest\n",
        "    time=time_interval,                       # Time interval\n",
        "    filter=\"eo:cloud_cover < 10\",             # Cloud cover < 10%\n",
        ")\n",
        "\n",
        "for row in search_iterator:\n",
        "    print(row)\n",
        "\n",
        "results = list(search_iterator)\n",
        "print(\"Total number of results:\", len(results))\n",
        "\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that even if we globally filter on the same parameters, the interface is much easier. And the actual cloud_cover value of the image is directly accessible.\n",
        "\n",
        "**In the other hand, no Quicklook in this catalog (for the moment?), so our OData Catalog search is still relevant.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Where Sentinel Hub will really shine : the Processing API\n",
        "\n",
        "Sentinel Hub have several API : Catalog, Statisical ... and Processing (cf. https://docs.sentinel-hub.com/api/latest/api/overview/).\n",
        "\n",
        "The Processing API allows you to **send a \"script\" to be evaluated in the cloud on the specified data** then the function return you directly the result of the calculation.\n",
        "\n",
        "Better, you don't have to specify a tile: if your bounding box is over several tiles, it will stich the corresponding tiles itself.\n",
        "\n",
        "Even better, if you give him a time interval, it can choose the less cloudy pixels from the period to make the calculation. (*Note that it means that you may have a resulting image that is composed of pixels from differents date !*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Example 1: True Color Image\n",
        "\n",
        "We build the request according to the [API Reference](https://docs.sentinel-hub.com/api/latest/reference/), using the `SentinelHubRequest` class. Each Process API request also needs an [evalscript](https://docs.sentinel-hub.com/api/latest/#/Evalscript/V3/README).\n",
        "\n",
        "The information that we specify in the `SentinelHubRequest` object is:\n",
        "- an evalscript,\n",
        "- a list of input data collections with time interval,\n",
        "- a format of the response,\n",
        "- a bounding box and it’s size (size or resolution).\n",
        "- `mosaickingOrder` (optional): in this example we have used `leastCC` which will return pixels from the least cloudy acquisition in the specified time period.\n",
        "\n",
        "The evalscript in the example is used to select the appropriate bands. We return the RGB (B04, B03, B02) Sentinel-2 L2A bands.\n",
        "\n",
        "The least cloudy image from the time period is downloaded. Without any additional parameters in the evalscript, the downloaded data will correspond to reflectance values in `UINT8` format (values in 0-255 range)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "evalscript_true_color = \"\"\"\n",
        "    //VERSION=3\n",
        "\n",
        "    function setup() {\n",
        "        return {\n",
        "            input: [{\n",
        "                bands: [\"B02\", \"B03\", \"B04\"]\n",
        "            }],\n",
        "            output: {\n",
        "                bands: 3\n",
        "            }\n",
        "        };\n",
        "    }\n",
        "\n",
        "    function evaluatePixel(sample) {\n",
        "        return [sample.B04, sample.B03, sample.B02];\n",
        "    }\n",
        "\"\"\"\n",
        "\n",
        "request_true_color = sentinelhub.SentinelHubRequest(\n",
        "    evalscript=evalscript_true_color,\n",
        "    input_data=[\n",
        "        sentinelhub.SentinelHubRequest.input_data(\n",
        "            data_collection=sentinelhub.DataCollection.SENTINEL2_L2A.define_from(\n",
        "                name=\"s2\", service_url=\"https://sh.dataspace.copernicus.eu\"\n",
        "            ),\n",
        "            time_interval=(start_date, end_date),\n",
        "            other_args={\"dataFilter\": {\"mosaickingOrder\": \"leastCC\"}}           )\n",
        "    ],\n",
        "    responses=[sentinelhub.SentinelHubRequest.output_response(\"default\", sentinelhub.MimeType.PNG)],\n",
        "    bbox=aoi_bbox_sh,\n",
        "    size=aoi_size, # WARNING, the output size should be < (2500,2500)\n",
        "    config=config,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The method `get_data()` will always return a list of length 1 with the available image from the requested time interval in the form of numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Returned data is of type = <class 'list'> and length 1.\n",
            "Single element in the list is of type <class 'numpy.ndarray'> / uint8 and has shape (1330, 577, 3)\n"
          ]
        }
      ],
      "source": [
        "true_color_imgs = request_true_color.get_data()\n",
        "\n",
        "print(f\"Returned data is of type = {type(true_color_imgs)} and length {len(true_color_imgs)}.\")\n",
        "print(f\"Single element in the list is of type {type(true_color_imgs[-1])} / {true_color_imgs[-1].dtype} and has shape {true_color_imgs[-1].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display the true_color_imgs (after applying a x3.5 factor on brightness for readability)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. Application to the analysis of the fire in La Teste-de-Buch "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the Sentinel Hub Processing API to produce:\n",
        "- For the time interval BEFORE the fire and AFTER the fire :\n",
        "  - The true color and false color images\n",
        "  - The NDVI ratio (Nice example at the end of this [Notebook](https://github.com/eu-cdse/notebook-samples/blob/c0e0ade601973c5d4e4bf66a13c0b76ebb099805/sentinelhub/migration_from_scihub_guide.ipynb), another proposition in this great [Custom scripts collections](https://custom-scripts.sentinel-hub.com/custom-scripts/hls/ndvi/))\n",
        "  - The Normalized Burn Ratio.  \n",
        "\n",
        "The formula of this last one is : **(NIR - SWIR) / (NIR + SWIR)**  \n",
        "\n",
        "If we want to use B12 with B08, we need to upsample the array. We could also use B8A which is 20m, but we want maximum precision.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you want, you can combine further the resulting images.\n",
        "\n",
        "You can also make some statistical calculation (% of the area burned per ex.)\n",
        "\n",
        "**Then, write a report based on what you can see/say on this situation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Second part of the lab : Do your own analysis !\n",
        "\n",
        "Find a subject (deforestation, oil spil, algae blooming, fire in canada/portugal/etc.) and make a study based on SENTINEL-2 images.\n",
        "\n",
        "Explain your idea and how you develop the pipeline adequately. Daring will be rewarded. (Choose fire detection in other region only if you don't feel confident on other subjects.)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
