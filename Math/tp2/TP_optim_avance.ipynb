{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus exercise (Advanced) - Acelerating SGD with Adam\n",
    "In this bonus exercise, you are supposed to implement a new GD solver, this time including in your gradient step a momentum term as well as a preconditioning scaler. In particular, you should implement the terms preconized in the Adam method.\n",
    "Refer to the exercises in TD2 for more information about Adam.\n",
    "\n",
    "Tip: inherit from the class GDminimizer and overload the appropriate methods in order to change the way the gradient step is computed.\n",
    "\n",
    "Once you have the new GD solver, use it to apply SGD to the least-squares regression on the housing dataset.\n",
    "\n",
    "Can you achieve a similar validation performance under less iterations? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
