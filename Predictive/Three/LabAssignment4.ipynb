{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOJg0qAE0-Ql"
      },
      "source": [
        "# Exercices\n",
        "You have 6 exercises in this lab assignment, 3 of which are optional.\n",
        "\n",
        "**Note**: Use `random_seed=42` so we all get the same results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPLM2m6Ph9NR"
      },
      "source": [
        "*Credits:* Based on [code written by A. Géron](https://github.com/ageron/handson-ml2) for his book \"\"Hands-on ML with scikit-learn, keras and tensorflow.\", 2nd edition 2019, O'Reilly Media. Code realeased under [Apache-2.0 License](https://github.com/ageron/handson-ml2/blob/master/LICENSE)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "h13UMb-Dh9rl"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import scipy as sp\n",
        "from scipy import stats\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gwCYH8Gfq1u"
      },
      "source": [
        "## Imbalanced classification with tree ensembles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdpmTM86fq1u"
      },
      "source": [
        "### Data\n",
        "[Predict students' dropout and academic success](https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nm-rE0xQfq1v",
        "outputId": "bed421b5-08a4-416b-fa3e-f187562c6d11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ucimlrepo in /home/zhangsanbao/miniforge3/envs/data_e/lib/python3.9/site-packages (0.0.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'uci_id': 697,\n",
              " 'name': \"Predict students' dropout and academic success\",\n",
              " 'repository_url': 'https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success',\n",
              " 'data_url': 'https://archive.ics.uci.edu/static/public/697/data.csv',\n",
              " 'abstract': \"A dataset created from a higher education institution (acquired from several disjoint databases) related to students enrolled in different undergraduate degrees, such as agronomy, design, education, nursing, journalism, management, social service, and technologies.\\nThe dataset includes information known at the time of student enrollment (academic path, demographics, and social-economic factors) and the students' academic performance at the end of the first and second semesters. \\nThe data is used to build classification models to predict students' dropout and academic sucess. The problem is formulated as a three category classification task, in which there is a strong imbalance towards one of the classes.\",\n",
              " 'area': 'Other',\n",
              " 'tasks': ['Classification'],\n",
              " 'characteristics': ['Tabular'],\n",
              " 'num_instances': 4424,\n",
              " 'num_features': 36,\n",
              " 'feature_types': [],\n",
              " 'demographics': ['Marital Status',\n",
              "  'Education Level',\n",
              "  'Nationality',\n",
              "  'Occupation',\n",
              "  'Gender',\n",
              "  'Age'],\n",
              " 'target_col': ['Target'],\n",
              " 'index_col': None,\n",
              " 'has_missing_values': 'no',\n",
              " 'missing_values_symbol': None,\n",
              " 'year_of_dataset_creation': 2021,\n",
              " 'last_updated': 'Mon Aug 28 2023',\n",
              " 'dataset_doi': '10.24432/C5MC89',\n",
              " 'creators': ['Valentim Realinho',\n",
              "  'Mónica Vieira Martins',\n",
              "  'Jorge Machado',\n",
              "  'Luís Baptista'],\n",
              " 'intro_paper': {'title': \"Early prediction of student's performance in higher education: a case study\",\n",
              "  'authors': 'Mónica V. Martins, Daniel Tolledo, Jorge Machado, Luís M. T. Baptista, and Valentim Realinho',\n",
              "  'published_in': 'Trends and Applications in Information Systems and Technologies',\n",
              "  'year': 2021,\n",
              "  'url': 'http://www.worldcist.org/2021/',\n",
              "  'doi': 'http://www.doi.org/10.1007/978-3-030-72657-7_16'},\n",
              " 'additional_info': {'summary': None,\n",
              "  'purpose': 'The dataset was created in a project that aims to contribute to the reduction of academic dropout and failure in higher education, by using machine learning techniques to identify students at risk at an early stage of their academic path, so that strategies to support them can be put into place. \\n\\nThe dataset includes information known at the time of student enrollment – academic path, demographics, and social-economic factors. \\n\\nThe problem is formulated as a three category classification task (dropout, enrolled, and graduate) at the end of the normal duration of the course. \\n',\n",
              "  'funded_by': 'This dataset is supported by program SATDAP - Capacitação da Administração Pública under grant POCI-05-5762-FSE-000191, Portugal.',\n",
              "  'instances_represent': 'Each instance is a student',\n",
              "  'recommended_data_splits': 'The dataset was used, in our project, with a data split of 80% for training and 20% for test.',\n",
              "  'sensitive_data': None,\n",
              "  'preprocessing_description': 'We performed a rigorous data preprocessing to handle data from anomalies, unexplainable outliers, and missing values.',\n",
              "  'variable_info': None,\n",
              "  'citation': 'If you use this dataset in experiments for a scientific publication, please kindly cite our paper: \\nM.V.Martins, D. Tolledo, J. Machado, L. M.T. Baptista, V.Realinho. (2021) \"Early prediction of student’s performance in higher education: a case study\" Trends and Applications in Information Systems and Technologies, vol.1, in Advances in Intelligent Systems and Computing series. Springer. DOI: 10.1007/978-3-030-72657-7_16'}}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>role</th>\n",
              "      <th>type</th>\n",
              "      <th>demographic</th>\n",
              "      <th>description</th>\n",
              "      <th>units</th>\n",
              "      <th>missing_values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Marital Status</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>Marital Status</td>\n",
              "      <td>1 – single 2 – married 3 – widower 4 – divorce...</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Application mode</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>1 - 1st phase - general contingent 2 - Ordinan...</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Application order</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>Application order (between 0 - first choice; a...</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Course</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>33 - Biofuel Production Technologies 171 - Ani...</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Daytime/evening attendance</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>1 – daytime 0 - evening</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Previous qualification</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>Education Level</td>\n",
              "      <td>1 - Secondary education 2 - Higher education -...</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Previous qualification (grade)</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Continuous</td>\n",
              "      <td>None</td>\n",
              "      <td>Grade of previous qualification (between 0 and...</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Nacionality</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>Nationality</td>\n",
              "      <td>1 - Portuguese; 2 - German; 6 - Spanish; 11 - ...</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Mother's qualification</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>Education Level</td>\n",
              "      <td>1 - Secondary Education - 12th Year of Schooli...</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Father's qualification</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>Education Level</td>\n",
              "      <td>1 - Secondary Education - 12th Year of Schooli...</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Mother's occupation</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>Occupation</td>\n",
              "      <td>0 - Student 1 - Representatives of the Legisla...</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Father's occupation</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>Occupation</td>\n",
              "      <td>0 - Student 1 - Representatives of the Legisla...</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Admission grade</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Continuous</td>\n",
              "      <td>None</td>\n",
              "      <td>Admission grade (between 0 and 200)</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Displaced</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>1 – yes 0 – no</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Educational special needs</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>1 – yes 0 – no</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Debtor</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>1 – yes 0 – no</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Tuition fees up to date</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>1 – yes 0 – no</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Gender</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>Gender</td>\n",
              "      <td>1 – male 0 – female</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Scholarship holder</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>1 – yes 0 – no</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Age at enrollment</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>Age</td>\n",
              "      <td>Age of studend at enrollment</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>International</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>1 – yes 0 – no</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Curricular units 1st sem (credited)</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>Number of curricular units credited in the 1st...</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Curricular units 1st sem (enrolled)</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>Number of curricular units enrolled in the 1st...</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Curricular units 1st sem (evaluations)</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>Number of evaluations to curricular units in t...</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Curricular units 1st sem (approved)</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>Number of curricular units approved in the 1st...</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Curricular units 1st sem (grade)</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>Grade average in the 1st semester (between 0 a...</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Curricular units 1st sem (without evaluations)</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>Number of curricular units without evalutions ...</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Curricular units 2nd sem (credited)</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>Number of curricular units credited in the 2nd...</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Curricular units 2nd sem (enrolled)</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>Number of curricular units enrolled in the 2nd...</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Curricular units 2nd sem (evaluations)</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>Number of evaluations to curricular units in t...</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Curricular units 2nd sem (approved)</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>Number of curricular units approved in the 2nd...</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Curricular units 2nd sem (grade)</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>Grade average in the 2nd semester (between 0 a...</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Curricular units 2nd sem (without evaluations)</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>Number of curricular units without evalutions ...</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Unemployment rate</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Continuous</td>\n",
              "      <td>None</td>\n",
              "      <td>Unemployment rate (%)</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Inflation rate</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Continuous</td>\n",
              "      <td>None</td>\n",
              "      <td>Inflation rate (%)</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>GDP</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Continuous</td>\n",
              "      <td>None</td>\n",
              "      <td>GDP</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Target</td>\n",
              "      <td>Target</td>\n",
              "      <td>Categorical</td>\n",
              "      <td>None</td>\n",
              "      <td>Target. The problem is formulated as a three c...</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              name     role         type  \\\n",
              "0                                   Marital Status  Feature      Integer   \n",
              "1                                 Application mode  Feature      Integer   \n",
              "2                                Application order  Feature      Integer   \n",
              "3                                           Course  Feature      Integer   \n",
              "4                       Daytime/evening attendance  Feature      Integer   \n",
              "5                           Previous qualification  Feature      Integer   \n",
              "6                   Previous qualification (grade)  Feature   Continuous   \n",
              "7                                      Nacionality  Feature      Integer   \n",
              "8                           Mother's qualification  Feature      Integer   \n",
              "9                           Father's qualification  Feature      Integer   \n",
              "10                             Mother's occupation  Feature      Integer   \n",
              "11                             Father's occupation  Feature      Integer   \n",
              "12                                 Admission grade  Feature   Continuous   \n",
              "13                                       Displaced  Feature      Integer   \n",
              "14                       Educational special needs  Feature      Integer   \n",
              "15                                          Debtor  Feature      Integer   \n",
              "16                         Tuition fees up to date  Feature      Integer   \n",
              "17                                          Gender  Feature      Integer   \n",
              "18                              Scholarship holder  Feature      Integer   \n",
              "19                               Age at enrollment  Feature      Integer   \n",
              "20                                   International  Feature      Integer   \n",
              "21             Curricular units 1st sem (credited)  Feature      Integer   \n",
              "22             Curricular units 1st sem (enrolled)  Feature      Integer   \n",
              "23          Curricular units 1st sem (evaluations)  Feature      Integer   \n",
              "24             Curricular units 1st sem (approved)  Feature      Integer   \n",
              "25                Curricular units 1st sem (grade)  Feature      Integer   \n",
              "26  Curricular units 1st sem (without evaluations)  Feature      Integer   \n",
              "27             Curricular units 2nd sem (credited)  Feature      Integer   \n",
              "28             Curricular units 2nd sem (enrolled)  Feature      Integer   \n",
              "29          Curricular units 2nd sem (evaluations)  Feature      Integer   \n",
              "30             Curricular units 2nd sem (approved)  Feature      Integer   \n",
              "31                Curricular units 2nd sem (grade)  Feature      Integer   \n",
              "32  Curricular units 2nd sem (without evaluations)  Feature      Integer   \n",
              "33                               Unemployment rate  Feature   Continuous   \n",
              "34                                  Inflation rate  Feature   Continuous   \n",
              "35                                             GDP  Feature   Continuous   \n",
              "36                                          Target   Target  Categorical   \n",
              "\n",
              "        demographic                                        description units  \\\n",
              "0    Marital Status  1 – single 2 – married 3 – widower 4 – divorce...  None   \n",
              "1              None  1 - 1st phase - general contingent 2 - Ordinan...  None   \n",
              "2              None  Application order (between 0 - first choice; a...  None   \n",
              "3              None  33 - Biofuel Production Technologies 171 - Ani...  None   \n",
              "4              None                            1 – daytime 0 - evening  None   \n",
              "5   Education Level  1 - Secondary education 2 - Higher education -...  None   \n",
              "6              None  Grade of previous qualification (between 0 and...  None   \n",
              "7       Nationality  1 - Portuguese; 2 - German; 6 - Spanish; 11 - ...  None   \n",
              "8   Education Level  1 - Secondary Education - 12th Year of Schooli...  None   \n",
              "9   Education Level  1 - Secondary Education - 12th Year of Schooli...  None   \n",
              "10       Occupation  0 - Student 1 - Representatives of the Legisla...  None   \n",
              "11       Occupation  0 - Student 1 - Representatives of the Legisla...  None   \n",
              "12             None                Admission grade (between 0 and 200)  None   \n",
              "13             None                                     1 – yes 0 – no  None   \n",
              "14             None                                     1 – yes 0 – no  None   \n",
              "15             None                                     1 – yes 0 – no  None   \n",
              "16             None                                     1 – yes 0 – no  None   \n",
              "17           Gender                                1 – male 0 – female  None   \n",
              "18             None                                     1 – yes 0 – no  None   \n",
              "19              Age                       Age of studend at enrollment  None   \n",
              "20             None                                     1 – yes 0 – no  None   \n",
              "21             None  Number of curricular units credited in the 1st...  None   \n",
              "22             None  Number of curricular units enrolled in the 1st...  None   \n",
              "23             None  Number of evaluations to curricular units in t...  None   \n",
              "24             None  Number of curricular units approved in the 1st...  None   \n",
              "25             None  Grade average in the 1st semester (between 0 a...  None   \n",
              "26             None  Number of curricular units without evalutions ...  None   \n",
              "27             None  Number of curricular units credited in the 2nd...  None   \n",
              "28             None  Number of curricular units enrolled in the 2nd...  None   \n",
              "29             None  Number of evaluations to curricular units in t...  None   \n",
              "30             None  Number of curricular units approved in the 2nd...  None   \n",
              "31             None  Grade average in the 2nd semester (between 0 a...  None   \n",
              "32             None  Number of curricular units without evalutions ...  None   \n",
              "33             None                              Unemployment rate (%)  None   \n",
              "34             None                                 Inflation rate (%)  None   \n",
              "35             None                                                GDP  None   \n",
              "36             None  Target. The problem is formulated as a three c...  None   \n",
              "\n",
              "   missing_values  \n",
              "0              no  \n",
              "1              no  \n",
              "2              no  \n",
              "3              no  \n",
              "4              no  \n",
              "5              no  \n",
              "6              no  \n",
              "7              no  \n",
              "8              no  \n",
              "9              no  \n",
              "10             no  \n",
              "11             no  \n",
              "12             no  \n",
              "13             no  \n",
              "14             no  \n",
              "15             no  \n",
              "16             no  \n",
              "17             no  \n",
              "18             no  \n",
              "19             no  \n",
              "20             no  \n",
              "21             no  \n",
              "22             no  \n",
              "23             no  \n",
              "24             no  \n",
              "25             no  \n",
              "26             no  \n",
              "27             no  \n",
              "28             no  \n",
              "29             no  \n",
              "30             no  \n",
              "31             no  \n",
              "32             no  \n",
              "33             no  \n",
              "34             no  \n",
              "35             no  \n",
              "36             no  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# fetch dataset\n",
        "%pip install ucimlrepo\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "predict_students_dropout_and_academic_success = fetch_ucirepo(id=697)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = predict_students_dropout_and_academic_success.data.features\n",
        "y = predict_students_dropout_and_academic_success.data.targets\n",
        "\n",
        "# metadata\n",
        "display(predict_students_dropout_and_academic_success.metadata)\n",
        "\n",
        "# variable information\n",
        "display(predict_students_dropout_and_academic_success.variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lMfgb74ufq1w",
        "outputId": "326057c4-6246-477b-ebdc-c45aa973f6fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Target. The problem is formulated as a three category classification task (dropout, enrolled, and graduate) at the end of the normal duration of the course'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_students_dropout_and_academic_success.variables.iloc[-1].loc[ 'description']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZgcGrZDffq1w",
        "outputId": "962d0af2-8f66-4f2d-b545-d2df35c1117f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([1421.,    0.,    0.,    0.,    0., 2209.,    0.,    0.,    0.,\n",
              "         794.]),\n",
              " array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. ]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mq9u9Wbfq1x"
      },
      "source": [
        "### Exercise\n",
        "1. For this dataset, try two types of tree ensembles:\n",
        "    - [`GradientBoostingClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)\n",
        "    - [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
        "1. Compare model scores on the training set vs the validation set. Are the models overfitting or underfitting?\n",
        "\n",
        "1. Choose a pertinent hyperparameter that you will adjust in order to reduce the problem you just diagnosed. Try a few values to see if you find a better model.\n",
        "\n",
        "1. Once you have found the best model, provide a detailed evaluation on the test set using the [`classification_report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html). Make sure you understand what each of the results mean.\n",
        "\n",
        "1. Imagine the main goal of this study is to be able to retrieve students in difficulty and help them _before_ they dropout. Altough it is not desirable to overload student counseling professionals (suppose they can provide guidance to 30% of the students), it is ok to send to counseling a student who would graduate just fine without it. Not noticing a student in difficulty is a greater problem that may lead to delayed graduation (the \"enroled\" class) or dropouts.\n",
        "    - Which metric would be the most appropriate to evaluate this goal?\n",
        "    - Which model scored best on this metric?\n",
        "\n",
        "1. It is possible to choose the probability threshold in order to trade-off precision for recall (or vice versa)\n",
        "    - focus on the \"Dropout\" class (i.e., use it as your positive class, the others will be negative)\n",
        "    - compute values of precision and recall for multiple tresholds using the function [`precision_recall_curve`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html)\n",
        "    - find out the threhold and the precision you get for 85% recall. Does it seem like a reasonable trade-off given the context of the application?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/zhangsanbao/miniforge3/envs/data_e/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/tmp/ipykernel_770/3862066314.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier()"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Split train set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#Create model\n",
        "gradient_boosting_model = GradientBoostingClassifier()\n",
        "random_forest_model = RandomForestClassifier()\n",
        "\n",
        "#Fit model\n",
        "gradient_boosting_model.fit(X_train, y_train)\n",
        "random_forest_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Boosting train accuracy: 0.844588866911557\n",
            "Boosting test accuracy: 0.7649717514124293\n",
            "Forest train accuracy: 1.0\n",
            "Forest test accuracy: 0.7762711864406779\n"
          ]
        }
      ],
      "source": [
        "boosting_train_predictions = gradient_boosting_model.predict(X_train)\n",
        "boosting_test_predictions = gradient_boosting_model.predict(X_test)\n",
        "boosting_train_accuracy = accuracy_score(y_train, boosting_train_predictions)\n",
        "boosting_test_accuracy = accuracy_score(y_test, boosting_test_predictions)\n",
        "print(\"Boosting train accuracy:\", boosting_train_accuracy)\n",
        "print(\"Boosting test accuracy:\", boosting_test_accuracy)\n",
        "\n",
        "forest_train_predictions = random_forest_model.predict(X_train)\n",
        "forest_test_predictions = random_forest_model.predict(X_test)\n",
        "forest_train_accuracy = accuracy_score(y_train, forest_train_predictions)\n",
        "forest_test_accuracy = accuracy_score(y_test, forest_test_predictions)\n",
        "print(\"Forest train accuracy:\", forest_train_accuracy)\n",
        "print(\"Forest test accuracy:\", forest_test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**For Boosting**\n",
        "\n",
        "The training accuracy is slightly below 1.0, which indicates that the model performed well on the training set, but did not fit the training data perfectly. The validation accuracy is lower than the training accuracy, but still relatively good. The model's training and validation accuracies are relatively close to each other, which indicates that the model does not have significant overfitting or underfitting problems and has good generalization ability.\n",
        "\n",
        "**For Forest**\n",
        "\n",
        "The training accuracy of the random forest model is 1.0, which indicates that it fits the training data perfectly on the training set. The validation accuracy shows that the model's performance on the validation set is low, with a significant gap relative to the training accuracy. Based on this information, it can be concluded that the Random Forest model may have an overfitting problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_deph=1, min_samples_leaf=10, min_samples_split=6\n",
            "Forest train accuracy: 0.6900254309126872\n",
            "Forest test accuracy: 0.672316384180791\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n",
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_deph=3, min_samples_leaf=10, min_samples_split=6\n",
            "Forest train accuracy: 0.7247810115851936\n",
            "Forest test accuracy: 0.711864406779661\n",
            "\n",
            "max_deph=5, min_samples_leaf=10, min_samples_split=6\n",
            "Forest train accuracy: 0.7719694829047754\n",
            "Forest test accuracy: 0.7389830508474576\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n",
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_deph=1, min_samples_leaf=15, min_samples_split=6\n",
            "Forest train accuracy: 0.6900254309126872\n",
            "Forest test accuracy: 0.672316384180791\n",
            "\n",
            "max_deph=3, min_samples_leaf=15, min_samples_split=6\n",
            "Forest train accuracy: 0.7244984458886691\n",
            "Forest test accuracy: 0.7107344632768362\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n",
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_deph=5, min_samples_leaf=15, min_samples_split=6\n",
            "Forest train accuracy: 0.764057643402091\n",
            "Forest test accuracy: 0.7389830508474576\n",
            "\n",
            "max_deph=1, min_samples_leaf=20, min_samples_split=6\n",
            "Forest train accuracy: 0.6900254309126872\n",
            "Forest test accuracy: 0.672316384180791\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n",
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_deph=3, min_samples_leaf=20, min_samples_split=6\n",
            "Forest train accuracy: 0.7244984458886691\n",
            "Forest test accuracy: 0.711864406779661\n",
            "\n",
            "max_deph=5, min_samples_leaf=20, min_samples_split=6\n",
            "Forest train accuracy: 0.7634925120090421\n",
            "Forest test accuracy: 0.7389830508474576\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n",
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_deph=1, min_samples_leaf=10, min_samples_split=12\n",
            "Forest train accuracy: 0.6900254309126872\n",
            "Forest test accuracy: 0.672316384180791\n",
            "\n",
            "max_deph=3, min_samples_leaf=10, min_samples_split=12\n",
            "Forest train accuracy: 0.7247810115851936\n",
            "Forest test accuracy: 0.711864406779661\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n",
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_deph=5, min_samples_leaf=10, min_samples_split=12\n",
            "Forest train accuracy: 0.7719694829047754\n",
            "Forest test accuracy: 0.7389830508474576\n",
            "\n",
            "max_deph=1, min_samples_leaf=15, min_samples_split=12\n",
            "Forest train accuracy: 0.6900254309126872\n",
            "Forest test accuracy: 0.672316384180791\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n",
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_deph=3, min_samples_leaf=15, min_samples_split=12\n",
            "Forest train accuracy: 0.7244984458886691\n",
            "Forest test accuracy: 0.7107344632768362\n",
            "\n",
            "max_deph=5, min_samples_leaf=15, min_samples_split=12\n",
            "Forest train accuracy: 0.764057643402091\n",
            "Forest test accuracy: 0.7389830508474576\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n",
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_deph=1, min_samples_leaf=20, min_samples_split=12\n",
            "Forest train accuracy: 0.6900254309126872\n",
            "Forest test accuracy: 0.672316384180791\n",
            "\n",
            "max_deph=3, min_samples_leaf=20, min_samples_split=12\n",
            "Forest train accuracy: 0.7244984458886691\n",
            "Forest test accuracy: 0.711864406779661\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n",
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_deph=5, min_samples_leaf=20, min_samples_split=12\n",
            "Forest train accuracy: 0.7634925120090421\n",
            "Forest test accuracy: 0.7389830508474576\n",
            "\n",
            "max_deph=1, min_samples_leaf=10, min_samples_split=18\n",
            "Forest train accuracy: 0.6900254309126872\n",
            "Forest test accuracy: 0.672316384180791\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n",
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_deph=3, min_samples_leaf=10, min_samples_split=18\n",
            "Forest train accuracy: 0.7247810115851936\n",
            "Forest test accuracy: 0.711864406779661\n",
            "\n",
            "max_deph=5, min_samples_leaf=10, min_samples_split=18\n",
            "Forest train accuracy: 0.7719694829047754\n",
            "Forest test accuracy: 0.7389830508474576\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n",
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_deph=1, min_samples_leaf=15, min_samples_split=18\n",
            "Forest train accuracy: 0.6900254309126872\n",
            "Forest test accuracy: 0.672316384180791\n",
            "\n",
            "max_deph=3, min_samples_leaf=15, min_samples_split=18\n",
            "Forest train accuracy: 0.7244984458886691\n",
            "Forest test accuracy: 0.7107344632768362\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n",
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_deph=5, min_samples_leaf=15, min_samples_split=18\n",
            "Forest train accuracy: 0.764057643402091\n",
            "Forest test accuracy: 0.7389830508474576\n",
            "\n",
            "max_deph=1, min_samples_leaf=20, min_samples_split=18\n",
            "Forest train accuracy: 0.6900254309126872\n",
            "Forest test accuracy: 0.672316384180791\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n",
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_deph=3, min_samples_leaf=20, min_samples_split=18\n",
            "Forest train accuracy: 0.7244984458886691\n",
            "Forest test accuracy: 0.711864406779661\n",
            "\n",
            "max_deph=5, min_samples_leaf=20, min_samples_split=18\n",
            "Forest train accuracy: 0.7634925120090421\n",
            "Forest test accuracy: 0.7389830508474576\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_770/1365001681.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "max_dep = [1, 3, 5]\n",
        "min_leaf = [10, 15, 20]\n",
        "min_split = [6, 12, 18]\n",
        "\n",
        "for split in min_split:\n",
        "    for leaf in min_leaf:\n",
        "        for m in max_dep:\n",
        "\n",
        "            random_forest_model = RandomForestClassifier(\n",
        "                max_depth=m, min_samples_leaf=leaf, min_samples_split=split, random_state=42)\n",
        "\n",
        "\n",
        "            random_forest_model.fit(X_train, y_train)\n",
        "            forest_train_predictions = random_forest_model.predict(X_train)\n",
        "\n",
        "            train_accuracy = accuracy_score(y_train, forest_train_predictions)\n",
        "            forest_train_accuracy = accuracy_score(\n",
        "                y_train, forest_train_predictions)\n",
        "            val_predictions = random_forest_model.predict(X_test)\n",
        "            val_accuracy = accuracy_score(y_test, val_predictions)\n",
        "            print(\n",
        "                f\"max_deph={m}, min_samples_leaf={leaf}, min_samples_split={split}\")\n",
        "            print(\"Forest train accuracy:\", forest_train_accuracy)\n",
        "            print(f\"Forest test accuracy: {val_accuracy}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_770/924229659.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_model.fit(X_train, y_train)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Forest train accuracy: 0.7634925120090421\n",
            "Forest test accuracy: 0.7389830508474576\n",
            "\n"
          ]
        }
      ],
      "source": [
        "random_forest_model = RandomForestClassifier(\n",
        "    max_depth=5, min_samples_leaf=20, min_samples_split=18, random_state=42)\n",
        "\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "forest_train_predictions = random_forest_model.predict(X_train)\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, forest_train_predictions)\n",
        "forest_train_accuracy = accuracy_score(\n",
        "    y_train, forest_train_predictions)\n",
        "val_predictions = random_forest_model.predict(X_test)\n",
        "val_accuracy = accuracy_score(y_test, val_predictions)\n",
        "print(\"Forest train accuracy:\", forest_train_accuracy)\n",
        "print(f\"Forest test accuracy: {val_accuracy}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Dropout       0.79      0.75      0.77       316\n",
            "    Enrolled       0.59      0.13      0.21       151\n",
            "    Graduate       0.72      0.95      0.82       418\n",
            "\n",
            "    accuracy                           0.74       885\n",
            "   macro avg       0.70      0.61      0.60       885\n",
            "weighted avg       0.72      0.74      0.70       885\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "report = classification_report(y_test, val_predictions)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Dropout       0.85      0.76      0.80       316\n",
            "    Enrolled       0.49      0.34      0.40       151\n",
            "    Graduate       0.78      0.92      0.84       418\n",
            "\n",
            "    accuracy                           0.76       885\n",
            "   macro avg       0.70      0.67      0.68       885\n",
            "weighted avg       0.75      0.76      0.75       885\n",
            "\n"
          ]
        }
      ],
      "source": [
        "report = classification_report(y_test, boosting_test_predictions)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The most appropriate metric to evaluate the objective is Recall, since the main goal is to try not to miss students in difficulty (Dropout category). Recall measures the model's ability to correctly detect students in difficulty. A high recall rate means that the model successfully finds most of the students in difficulty, even if it is acceptable to misreport some students who do not need intervention, since failure to intervene in a timely manner may result in students dropping out.\n",
        "Also, given that the main goal is to reduce dropout rates, the F1 score is a useful metric because it combines precision and recall. A high F1 score indicates that the model performs well in terms of false positives while correctly detecting students in difficulty."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the two key metrics, recall and F1 score, the Boosting model scores higher on this particular objective and may be more appropriate in reducing dropout rates relative to the Forest model. However, the difference in performance between the two is not significant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recall 0.85 Threshold: 0.0041\n",
            "Precision: 0.3571\n",
            "Recall 0.85 Threshold: 0.0263\n",
            "Precision: 0.3571\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "y_positive_class = (y_test == 'Dropout')\n",
        "y_probabilities = gradient_boosting_model.predict_proba(X_test)[:, 1]\n",
        "precision, recall, thresholds = precision_recall_curve(y_positive_class, y_probabilities)\n",
        "target_recall = 0.85\n",
        "idx = np.argmax(recall >= target_recall)\n",
        "chosen_threshold = thresholds[idx]\n",
        "chosen_precision = precision[idx]\n",
        "print(f\"Recall {target_recall:.2f} Threshold: {chosen_threshold:.4f}\")\n",
        "print(f\"Precision: {chosen_precision:.4f}\")\n",
        "\n",
        "y_probabilities = random_forest_model.predict_proba(X_test)[:, 1]\n",
        "precision, recall, thresholds = precision_recall_curve(y_positive_class, y_probabilities)\n",
        "target_recall = 0.85\n",
        "idx = np.argmax(recall >= target_recall)\n",
        "chosen_threshold = thresholds[idx]\n",
        "chosen_precision = precision[idx]\n",
        "print(f\"Recall {target_recall:.2f} Threshold: {chosen_threshold:.4f}\")\n",
        "print(f\"Precision: {chosen_precision:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that although the thresholds are low, the accuracy of both models is poor, which means that we will have a high probability of selecting unwanted students."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA1P9BQPfq1x"
      },
      "source": [
        "## (Optional) Feature importance on tree ensembles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0MI1XWyfq1x"
      },
      "source": [
        "### Exercise\n",
        "Now that you have chosen the best model, let's retrieve which attributes are the main predictors of a student dropping out. This means we want to estimate *feature importance*. With tree ensembles, there are two main ways of doing so.\n",
        "\n",
        "1. Compute feature importances using the [permutation importance](https://scikit-learn.org/stable/modules/permutation_importance.html). Get the top-10 most important features.\n",
        "\n",
        "2. Compute feature importances following [\"mean decrease in impurity (MDI)\"](https://scikit-learn.org/stable/modules/ensemble.html#feature-importance-evaluation). These get precomputed during `fit`, and are based on the training set only. Get the feature importances computed from the random forest model trained before, and check the top-10 most important features. Are they the same as with the permutation method? Is their rank the same?\n",
        "\n",
        "3. `sklearn`'s documentation warns about two main caveats of using MDI to estimate feature importance. Did you notice them in the docs? Which are they?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXmHwioGiHMB"
      },
      "source": [
        "## Voting Classifier on MNIST\n",
        "### Data\n",
        "This exercise uses the MNIST dataset: a set of 28x28 images containing hadnwritten 0-9 digits. It can be loaded using `sklearn` functions as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayAS552Dui88"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# Load data from https://www.openml.org/d/554\n",
        "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgUdHMaUui88"
      },
      "source": [
        "Here the feaures in X are simply all the 784 pixels of any given image, in vectorized form. To visualize the orignal image, the vector must be reshaped back to a 2D array as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9onb8CZui89"
      },
      "outputs": [],
      "source": [
        "plt.imshow(X[0, :].reshape([28, 28]), cmap='Greys')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjxqgeFOui8-"
      },
      "source": [
        "**The goal** is to correctly predict the digit from the image pixels. This is what you have in the y array:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rJOzgxhui8-"
      },
      "outputs": [],
      "source": [
        "y[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w47zu-fWui8_"
      },
      "source": [
        "### Feture range and scaling\n",
        "In general, that pixel values here range in 0-255. However, since digits are always cented, pixels in the center of the image tend to have a larger variance than those at the border. To visualize this, observe the plotting of the stddev for each pixel across all images. See how pixels at the border have near 0 variance while  those at the center have a much large one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEgJQifsui9A"
      },
      "outputs": [],
      "source": [
        "plt.imshow(X.std(axis=0).reshape([28,28]))\n",
        "plt.colorbar()\n",
        "plt.title(\"Standard deviation per image location\\n (i.e. per feature)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJuyEUgLui9A"
      },
      "source": [
        "Remember models trained with continuous optimization (especially 1st order methods) benefit from features having a similar range (because this leads to better conditioned cost functions). For these methods **it is recommended that you apply some form of feature scaling**. For example, after applying standard scaling, variances become mostly equal to 1, meaning all features lie in a similar range:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_4K3U5eui9B"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_scaled = StandardScaler().fit_transform(X)\n",
        "\n",
        "plt.imshow(X_scaled.std(axis=0).reshape([28,28]))\n",
        "plt.colorbar()\n",
        "plt.title(\"Standard deviation per image location\\n (i.e. per feature)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0Eg_8Z6fq1z"
      },
      "source": [
        "Note that some pixels still have 0 standard deviation. This happens because they are always zero across all images. We will further process the data to remove these pixel features from our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pP_sMgnZfq1z"
      },
      "outputs": [],
      "source": [
        "X_scaled = X_scaled[: , X_scaled.std(axis=0) != 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUsDo_Dqfq10"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "\n",
        "1. Load the MNIST data and split it into a training set, a validation set, and a test set (e.g., use 50,000 instances for training, 10,000 for validation, and 10,000 for testing).\n",
        "\n",
        "1. Fit a voting ensemble combining multple models. Include:  \n",
        "    - a [`RandomForestClassifier`](),\n",
        "    - an [`ExtraTreesClassifier`](),\n",
        "    - and a [`LinearSVC`]().\n",
        "\n",
        "\n",
        "1. Evaluate the accuracy of the ensemble model and compare it to that if its member models. Does the ensemble outperform all of the included models?\n",
        "\n",
        "1. Remove the weakest model of the ensemble, then re-evaluate the ensemble's accuracy. Did it get better?\n",
        "\n",
        "1. Try using soft voting this time and compare the accuracy to hard voting. Does soft voting outperform all individual models?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YBsBPpXfq10"
      },
      "source": [
        "## Stacking Ensemble on MNIST\n",
        "1. Using the same estimators as the previous voting classifier, now train a stacking ensemble. Use a logsitic regression as your blender model.\n",
        "\n",
        "1. How does it compare to the voting classifier you trained earlier?\n",
        "\n",
        "1. You have tried 3 different voting ensembles and a stacking ensemble. Which one would you choose for deployment? Estimate the expected generalization performance by evaluating the best ensemble on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSeZPqw_Qv0I"
      },
      "source": [
        "## (Optional) Train and fine-tune a decision tree\n",
        "Train and fine-tune a Decision Tree for the moons dataset by following these steps:  \n",
        "  1. Use `make_moons(n_samples=10000, noise=0.4)` to generate a moons dataset.   \n",
        "  1. Use `train_test_split()` to split the dataset into a training set and a test set.\n",
        "  1. Use grid search with cross-validation (with the help of the `GridSearchCV` class) to find good hyperparameter values for a `DecisionTreeClassifier`. Hint: try various values for `max_leaf_nodes`.\n",
        "  1. Train it on the full training set using these hyperparameters, and measure your model's performance on the test set. You should get roughly 85% to 87% accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4wJJZPrRCzo"
      },
      "source": [
        "## (Optional) Grow your own random forest\n",
        "Grow a forest by following these steps:  \n",
        "  \n",
        "  1. Continuing the previous exercise, generate 1,000 subsets of the training set, each containing 100 instances selected randomly. *Hint*: you can use ScikitLearn’s `ShuffleSplit` class for this.  \n",
        "  1. Train one Decision Tree on each subset, using the best hyperparameter values found in the previous exercise. Evaluate these 1,000 Decision Trees on the test set. Since they were trained on smaller sets, these Decision Trees will likely perform worse than the first Decision Tree, achieving only about 80% accuracy.  \n",
        "  1. Now comes the magic. For each test set instance, generate the predictions of the 1,000 Decision Trees, and keep only the most frequent prediction (you can use SciPy’s `mode()` function for this). This approach gives you majority-vote predictions over the test set.  \n",
        "  1. Evaluate these predictions on the test set: you should obtain a slightly higher accuracy than your first model (about 0.5 to 1.5% higher). Congratulations, you have trained a Random Forest classifier!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "LabAssignment4.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('ml-latest')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "1bede9cc09fadb76754e231ea17b3d1b4d36d88785eed308e26382b97c73c356"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
